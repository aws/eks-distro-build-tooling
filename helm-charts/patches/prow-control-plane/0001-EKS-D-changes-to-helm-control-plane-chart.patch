From aee2f095d9d0f6465581ac12c2acee52afc60034 Mon Sep 17 00:00:00 2001
From: Mark Pruett <mpruett@amazon.com>
Date: Wed, 28 Dec 2022 11:16:51 -0600
Subject: [PATCH] EKS-D Changes to Helm control plane chart

Signed-off-by: Mark Pruett <mpruett@amazon.com>
---
 config/prow/cluster/crier_deployment.yaml     |  89 ++++++++------
 config/prow/cluster/crier_rbac.yaml           |  44 +------
 config/prow/cluster/deck_deployment.yaml      | 114 +++++++++---------
 config/prow/cluster/deck_rbac.yaml            |  38 +-----
 config/prow/cluster/deck_service.yaml         |  11 +-
 config/prow/cluster/ghproxy.yaml              |  35 +++---
 config/prow/cluster/hook_deployment.yaml      |  89 ++++++--------
 config/prow/cluster/hook_rbac.yaml            |   6 +-
 config/prow/cluster/hook_service.yaml         |  12 +-
 .../prow/cluster/horologium_deployment.yaml   |  21 +++-
 config/prow/cluster/horologium_rbac.yaml      |   6 +-
 .../prow_controller_manager_deployment.yaml   |  84 +++++++------
 .../cluster/prow_controller_manager_rbac.yaml |  41 ++-----
 config/prow/cluster/sinker_deployment.yaml    |  78 ++++++------
 config/prow/cluster/sinker_rbac.yaml          |  39 ++----
 .../cluster/statusreconciler_deployment.yaml  |  29 +++--
 .../prow/cluster/statusreconciler_rbac.yaml   |   6 +-
 config/prow/cluster/tide_deployment.yaml      |  38 ++++--
 config/prow/cluster/tide_rbac.yaml            |   8 +-
 config/prow/cluster/tide_service.yaml         |  11 +-
 config/prow/config.yaml                       |   2 +-
 21 files changed, 353 insertions(+), 448 deletions(-)

diff --git a/config/prow/cluster/crier_deployment.yaml b/config/prow/cluster/crier_deployment.yaml
index 4405f98e78..fcd659aa4b 100644
--- a/config/prow/cluster/crier_deployment.yaml
+++ b/config/prow/cluster/crier_deployment.yaml
@@ -15,7 +15,6 @@
 apiVersion: apps/v1
 kind: Deployment
 metadata:
-  namespace: default
   name: crier
   labels:
     app: crier
@@ -26,6 +25,12 @@ spec:
       app: crier
   template:
     metadata:
+      {{- if .Values.crier.scrape_metrics }}
+      annotations:
+        prometheus.io/path: /metrics
+        prometheus.io/port: '9090'
+        prometheus.io/scrape: 'true'
+      {{- end }}
       labels:
         app: crier
     spec:
@@ -33,50 +38,61 @@ spec:
       terminationGracePeriodSeconds: 30
       containers:
       - name: crier
-        image: gcr.io/k8s-prow/crier:v20221104-4497ace285
+        image: {{ .Values.crier.image }}
         args:
-        - --blob-storage-workers=1
+        - --blob-storage-workers=10
         - --config-path=/etc/config/config.yaml
         - --github-endpoint=http://ghproxy
         - --github-endpoint=https://api.github.com
-        - --github-token-path=/etc/github/oauth
-        - --github-workers=5
+        - --github-token-path=/etc/github/token
+        - --github-workers=10
         - --job-config-path=/etc/job-config
-        - --kubernetes-blob-storage-workers=1
+        - --kubeconfig=/etc/kubeconfig/config
+        - --kubernetes-blob-storage-workers=10
+        - --s3-credentials-file=/etc/s3-credentials/service-account.json
         - --slack-token-file=/etc/slack/token
         - --slack-workers=1
         env:
-        # Use KUBECONFIG envvar rather than --kubeconfig flag in order to provide multiple configs to merge.
-        - name: KUBECONFIG
-          value: "/etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig:/etc/kubeconfig-build-k8s-prow-builds/kubeconfig:/etc/kubeconfig-build-rules-k8s/kubeconfig"
-        ports:
-        - name: metrics
-          containerPort: 9090
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        - name: AWS_ROLE_SESSION_NAME
+          valueFrom:
+            fieldRef:
+              fieldPath: metadata.name
         volumeMounts:
-        - mountPath: /etc/kubeconfig
-          name: kubeconfig
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-test-infra-trusted
-          name: kubeconfig-build-test-infra-trusted
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-k8s-prow-builds
-          name: kubeconfig-build-k8s-prow-builds
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-rules-k8s
-          name: kubeconfig-build-rules-k8s
-          readOnly: true
         - name: config
           mountPath: /etc/config
           readOnly: true
         - name: job-config
           mountPath: /etc/job-config
           readOnly: true
-        - name: oauth
+        - name: github-token
           mountPath: /etc/github
           readOnly: true
+        - name: s3-credentials
+          mountPath: /etc/s3-credentials
+          readOnly: true
         - name: slack
           mountPath: /etc/slack
           readOnly: true
+        - name: kubeconfig
+          mountPath: /etc/kubeconfig
+          readOnly: true
+        - name: shared-bins
+          mountPath: /shared-bins
+      initContainers:
+      - name: aws-iam-authenticator
+        env:
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        image: {{ .Values.awsIamAuthenticator.image }}
+        command:
+        - cp
+        - /aws-iam-authenticator
+        - /shared-bins/aws-iam-authenticator
+        volumeMounts:
+        - name: shared-bins
+          mountPath: /shared-bins
       volumes:
       - name: config
         configMap:
@@ -84,25 +100,18 @@ spec:
       - name: job-config
         configMap:
           name: job-config
-      - name: oauth
+      - name: github-token
+        secret:
+          secretName: github-token
+      - name: s3-credentials
         secret:
-          secretName: oauth-token
+          secretName: s3-credentials
       - name: slack
         secret:
           secretName: slack-token
+      - name: shared-bins
+        emptyDir: {}
       - name: kubeconfig
         secret:
-          defaultMode: 420
+          defaultMode: 0644
           secretName: kubeconfig
-      - name: kubeconfig-build-test-infra-trusted
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-test-infra-trusted
-      - name: kubeconfig-build-k8s-prow-builds
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-k8s-prow-builds
-      - name: kubeconfig-build-rules-k8s
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-rules-k8s
diff --git a/config/prow/cluster/crier_rbac.yaml b/config/prow/cluster/crier_rbac.yaml
index 53f4471080..57393297a9 100644
--- a/config/prow/cluster/crier_rbac.yaml
+++ b/config/prow/cluster/crier_rbac.yaml
@@ -13,18 +13,16 @@
 # limitations under the License.
 
 ---
+{{ if .Values.crier.serviceAccount.create }}
 kind: ServiceAccount
 apiVersion: v1
 metadata:
-  annotations:
-    iam.gke.io/gcp-service-account: control-plane@k8s-prow.iam.gserviceaccount.com
   name: crier
-  namespace: default
+{{ end }}
 ---
 kind: Role
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: crier
 rules:
 - apiGroups:
@@ -37,46 +35,10 @@ rules:
     - "list"
     - "patch"
 ---
-kind: Role
-apiVersion: rbac.authorization.k8s.io/v1
-metadata:
-  namespace: test-pods
-  name: crier
-rules:
-- apiGroups:
-    - ""
-  resources:
-    - "pods"
-    - "events"
-  verbs:
-    - "get"
-    - "list"
-- apiGroups:
-    - ""
-  resources:
-    - "pods"
-  verbs:
-    - "patch"
----
 kind: RoleBinding
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  name: crier-namespaced
-  namespace: default
-roleRef:
-  apiGroup: rbac.authorization.k8s.io
-  kind: Role
-  name: crier
-subjects:
-- kind: ServiceAccount
   name: crier
-  namespace: default
----
-kind: RoleBinding
-apiVersion: rbac.authorization.k8s.io/v1
-metadata:
-  name: crier-namespaced
-  namespace: test-pods
 roleRef:
   apiGroup: rbac.authorization.k8s.io
   kind: Role
@@ -84,4 +46,4 @@ roleRef:
 subjects:
 - kind: ServiceAccount
   name: crier
-  namespace: default
+  namespace: {{ .Release.Namespace }}
diff --git a/config/prow/cluster/deck_deployment.yaml b/config/prow/cluster/deck_deployment.yaml
index a37074bbb8..e829c32a53 100644
--- a/config/prow/cluster/deck_deployment.yaml
+++ b/config/prow/cluster/deck_deployment.yaml
@@ -15,12 +15,11 @@
 apiVersion: apps/v1
 kind: Deployment
 metadata:
-  namespace: default
   name: deck
   labels:
     app: deck
 spec:
-  replicas: 3
+  replicas: 2
   strategy:
     type: RollingUpdate
     rollingUpdate:
@@ -31,6 +30,12 @@ spec:
       app: deck
   template:
     metadata:
+      {{- if .Values.deck.scrape_metrics }}
+      annotations:
+        prometheus.io/path: /metrics
+        prometheus.io/port: '9090'
+        prometheus.io/scrape: 'true'
+      {{- end }}
       labels:
         app: deck
     spec:
@@ -38,63 +43,52 @@ spec:
       terminationGracePeriodSeconds: 30
       containers:
       - name: deck
-        image: gcr.io/k8s-prow/deck:v20221104-4497ace285
+        image: {{ .Values.deck.image }}
         imagePullPolicy: Always
         ports:
-        - name: http
-          containerPort: 8080
-        - name: metrics
-          containerPort: 9090
+          - name: http
+            containerPort: 8080
         args:
+        - --kubeconfig=/etc/kubeconfig/config
         - --tide-url=http://tide/
         - --hook-url=http://hook:8888/plugin-help
-        - --redirect-http-to=prow.k8s.io
-        - --oauth-url=/github-login
         - --config-path=/etc/config/config.yaml
         - --job-config-path=/etc/job-config
         - --spyglass=true
-        - --rerun-creates-job
-        - --github-token-path=/etc/github/oauth
+        - --github-token-path=/etc/github/token
         - --github-endpoint=http://ghproxy
         - --github-endpoint=https://api.github.com
-        - --github-oauth-config-file=/etc/githuboauth/secret
-        - --cookie-secret=/etc/cookie/secret
         - --plugin-config=/etc/plugins/plugins.yaml
+        - --github-graphql-endpoint=http://ghproxy/graphql
+        - --s3-credentials-file=/etc/s3-credentials/service-account.json
         env:
-        # Use KUBECONFIG envvar rather than --kubeconfig flag in order to provide multiple configs to merge.
-        - name: KUBECONFIG
-          value: "/etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig:/etc/kubeconfig-build-k8s-prow-builds/kubeconfig:/etc/kubeconfig-build-rules-k8s/kubeconfig"
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        - name: AWS_ROLE_SESSION_NAME
+          valueFrom:
+            fieldRef:
+              fieldPath: metadata.name
         volumeMounts:
-        - name: oauth-config
-          mountPath: /etc/githuboauth
-          readOnly: true
-        - name: cookie-secret
-          mountPath: /etc/cookie
-          readOnly: true
-        - mountPath: /etc/kubeconfig
-          name: kubeconfig
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-test-infra-trusted
-          name: kubeconfig-build-test-infra-trusted
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-k8s-prow-builds
-          name: kubeconfig-build-k8s-prow-builds
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-rules-k8s
-          name: kubeconfig-build-rules-k8s
-          readOnly: true
         - name: config
           mountPath: /etc/config
           readOnly: true
         - name: job-config
           mountPath: /etc/job-config
           readOnly: true
-        - name: oauth-token
+        - name: github-token
           mountPath: /etc/github
           readOnly: true
         - name: plugins
           mountPath: /etc/plugins
           readOnly: true
+        - name: s3-credentials
+          mountPath: /etc/s3-credentials
+          readOnly: true
+        - name: kubeconfig
+          mountPath: /etc/kubeconfig
+          readOnly: true
+        - name: shared-bins
+          mountPath: /shared-bins
         livenessProbe:
           httpGet:
             path: /healthz
@@ -108,32 +102,20 @@ spec:
           initialDelaySeconds: 10
           periodSeconds: 3
           timeoutSeconds: 600
+      initContainers:
+      - name: aws-iam-authenticator
+        env:
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        image: {{ .Values.awsIamAuthenticator.image }}
+        command:
+        - cp
+        - /aws-iam-authenticator
+        - /shared-bins/aws-iam-authenticator
+        volumeMounts:
+        - name: shared-bins
+          mountPath: /shared-bins
       volumes:
-      - name: oauth-config
-        secret:
-          secretName: github-oauth-config
-      - name: oauth-token
-        secret:
-          secretName: oauth-token
-      - name: cookie-secret
-        secret:
-          secretName: cookie
-      - name: kubeconfig
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig
-      - name: kubeconfig-build-test-infra-trusted
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-test-infra-trusted
-      - name: kubeconfig-build-k8s-prow-builds
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-k8s-prow-builds
-      - name: kubeconfig-build-rules-k8s
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-rules-k8s
       - name: config
         configMap:
           name: config
@@ -143,3 +125,15 @@ spec:
       - name: plugins
         configMap:
           name: plugins
+      - name: github-token
+        secret:
+          secretName: github-token
+      - name: s3-credentials
+        secret:
+          secretName: s3-credentials
+      - name: shared-bins
+        emptyDir: {}
+      - name: kubeconfig
+        secret:
+          defaultMode: 0644
+          secretName: kubeconfig
diff --git a/config/prow/cluster/deck_rbac.yaml b/config/prow/cluster/deck_rbac.yaml
index 6c7456d47b..d1a8489a38 100644
--- a/config/prow/cluster/deck_rbac.yaml
+++ b/config/prow/cluster/deck_rbac.yaml
@@ -1,15 +1,13 @@
+{{ if .Values.deck.serviceAccount.create }}
 apiVersion: v1
 kind: ServiceAccount
 metadata:
-  namespace: default
-  annotations:
-    iam.gke.io/gcp-service-account: control-plane@k8s-prow.iam.gserviceaccount.com
   name: deck
+{{ end }}
 ---
 kind: Role
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: deck
 rules:
 - apiGroups:
@@ -20,39 +18,11 @@ rules:
   - get
   - list
   - watch
-  # Required when deck runs with `--rerun-creates-job=true`
-  - create
----
-kind: Role
-apiVersion: rbac.authorization.k8s.io/v1
-metadata:
-  namespace: test-pods
-  name: deck
-rules:
-- apiGroups:
-  - ""
-  resources:
-  - pods/log
-  verbs:
-  - get
----
-kind: RoleBinding
-apiVersion: rbac.authorization.k8s.io/v1
-metadata:
-  namespace: default
-  name: deck
-roleRef:
-  apiGroup: rbac.authorization.k8s.io
-  kind: Role
-  name: deck
-subjects:
-- kind: ServiceAccount
-  name: deck
+  - patch
 ---
 kind: RoleBinding
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: test-pods
   name: deck
 roleRef:
   apiGroup: rbac.authorization.k8s.io
@@ -61,4 +31,4 @@ roleRef:
 subjects:
 - kind: ServiceAccount
   name: deck
-  namespace: default
+  namespace: {{ .Release.Namespace }}
diff --git a/config/prow/cluster/deck_service.yaml b/config/prow/cluster/deck_service.yaml
index e65a50ebcb..8a418f3b6c 100644
--- a/config/prow/cluster/deck_service.yaml
+++ b/config/prow/cluster/deck_service.yaml
@@ -15,19 +15,10 @@
 apiVersion: v1
 kind: Service
 metadata:
-  labels:
-    app: deck
-  namespace: default
   name: deck
 spec:
   selector:
     app: deck
   ports:
-  - name: main
-    port: 80
+  - port: 80
     targetPort: 8080
-    protocol: TCP
-  - name: metrics
-    port: 9090
-    protocol: TCP
-  type: NodePort
diff --git a/config/prow/cluster/ghproxy.yaml b/config/prow/cluster/ghproxy.yaml
index 61cc8368a4..b8cbbc4ea6 100644
--- a/config/prow/cluster/ghproxy.yaml
+++ b/config/prow/cluster/ghproxy.yaml
@@ -15,7 +15,6 @@
 kind: PersistentVolumeClaim
 apiVersion: v1
 metadata:
-  namespace: default
   labels:
     app: ghproxy
   name: ghproxy
@@ -24,7 +23,7 @@ spec:
     - ReadWriteOnce
   resources:
     requests:
-      storage: 100Gi
+      storage: {{ .Values.ghproxy.volumeSize }}Gi
   # gce-ssd-retain is specified in config/prow/cluster/gce-ssd-retain_storageclass.yaml
   #
   # If you are setting up your own Prow instance you can do any of the following:
@@ -32,12 +31,11 @@ spec:
   # 2) Specify your own storage class.
   # 3) If you are using GKE you can use the gce-ssd-retain storage class. It can be
   #    created with: `kubectl create -f config/prow/cluster/gce-ssd-retain_storageclass.yaml
-  storageClassName: gce-ssd-retain
+#  storageClassName: gce-ssd-retain
 ---
 apiVersion: apps/v1
 kind: Deployment
 metadata:
-  namespace: default
   name: ghproxy
   labels:
     app: ghproxy
@@ -45,20 +43,36 @@ spec:
   selector:
     matchLabels:
       app: ghproxy
+  strategy:
+    type: Recreate
+  # GHProxy does not support HA
   replicas: 1  # TODO(fejta): this should be HA
   template:
     metadata:
+      {{- if .Values.ghproxy.scrape_metrics }}
+      annotations:
+        prometheus.io/path: /metrics
+        prometheus.io/port: '9090'
+        prometheus.io/scrape: 'true'
+      {{- end }}
       labels:
         app: ghproxy
     spec:
       containers:
       - name: ghproxy
-        image: gcr.io/k8s-prow/ghproxy:v20221104-4497ace285
+        image: {{ .Values.ghproxy.image }}
         args:
         - --cache-dir=/cache
-        - --cache-sizeGB=99
+        - --cache-sizeGB={{ add .Values.ghproxy.volumeSize -1 }}
         - --push-gateway=pushgateway
         - --serve-metrics=true
+        env:
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        - name: AWS_ROLE_SESSION_NAME
+          valueFrom:
+            fieldRef:
+              fieldPath: metadata.name
         ports:
         - name: main
           containerPort: 8888
@@ -71,21 +85,12 @@ spec:
       - name: cache
         persistentVolumeClaim:
           claimName: ghproxy
-      # run on our dedicated node
-      tolerations:
-      - key: "dedicated"
-        operator: "Equal"
-        value: "ghproxy"
-        effect: "NoSchedule"
-      nodeSelector:
-        dedicated: "ghproxy"
 ---
 apiVersion: v1
 kind: Service
 metadata:
   labels:
     app: ghproxy
-  namespace: default
   name: ghproxy
 spec:
   ports:
diff --git a/config/prow/cluster/hook_deployment.yaml b/config/prow/cluster/hook_deployment.yaml
index 3884d90bce..8333694b39 100644
--- a/config/prow/cluster/hook_deployment.yaml
+++ b/config/prow/cluster/hook_deployment.yaml
@@ -15,12 +15,11 @@
 apiVersion: apps/v1
 kind: Deployment
 metadata:
-  namespace: default
   name: hook
   labels:
     app: hook
 spec:
-  replicas: 4
+  replicas: 2
   strategy:
     type: RollingUpdate
     rollingUpdate:
@@ -31,6 +30,12 @@ spec:
       app: hook
   template:
     metadata:
+      {{- if .Values.hook.scrape_metrics }}
+      annotations:
+        prometheus.io/path: /metrics
+        prometheus.io/port: '9090'
+        prometheus.io/scrape: 'true'
+      {{- end }}
       labels:
         app: hook
     spec:
@@ -38,32 +43,33 @@ spec:
       terminationGracePeriodSeconds: 180
       containers:
       - name: hook
-        image: gcr.io/k8s-prow/hook:v20221104-4497ace285
+        image: {{ .Values.hook.image }}
         imagePullPolicy: Always
         args:
-        - --dry-run=false
-        - --slack-token-file=/etc/slack/token
+        - --kubeconfig=/etc/kubeconfig/config
+        - --dry-run={{ .Values.dryRun }}
         - --github-endpoint=http://ghproxy
         - --github-endpoint=https://api.github.com
-        - --github-token-path=/etc/github/oauth
+        - --github-token-path=/etc/github/token
         - --config-path=/etc/config/config.yaml
         - --job-config-path=/etc/job-config
         env:
-        # Use KUBECONFIG envvar rather than --kubeconfig flag in order to provide multiple configs to merge.
-        - name: KUBECONFIG
-          value: "/etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig:/etc/kubeconfig-build-k8s-prow-builds/kubeconfig:/etc/kubeconfig-build-rules-k8s/kubeconfig"
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        - name: AWS_ROLE_SESSION_NAME
+          valueFrom:
+            fieldRef:
+              fieldPath: metadata.name
         ports:
         - name: http
           containerPort: 8888
         - name: metrics
           containerPort: 9090
         volumeMounts:
-        - name: slack
-          mountPath: /etc/slack
         - name: hmac
           mountPath: /etc/webhook
           readOnly: true
-        - name: oauth
+        - name: github-token
           mountPath: /etc/github
           readOnly: true
         - name: config
@@ -75,24 +81,11 @@ spec:
         - name: plugins
           mountPath: /etc/plugins
           readOnly: true
-        - name: cat-api
-          mountPath: /etc/cat-api
-          readOnly: true
-        - name: unsplash-api
-          mountPath: /etc/unsplash-api
-          readOnly: true
         - name: kubeconfig
           mountPath: /etc/kubeconfig
           readOnly: true
-        - mountPath: /etc/kubeconfig-build-test-infra-trusted
-          name: kubeconfig-build-test-infra-trusted
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-k8s-prow-builds
-          name: kubeconfig-build-k8s-prow-builds
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-rules-k8s
-          name: kubeconfig-build-rules-k8s
-          readOnly: true
+        - name: shared-bins
+          mountPath: /shared-bins
         livenessProbe:
           httpGet:
             path: /healthz
@@ -106,16 +99,26 @@ spec:
           initialDelaySeconds: 10
           periodSeconds: 3
           timeoutSeconds: 600
+      initContainers:
+      - name: aws-iam-authenticator
+        env:
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        image: {{ .Values.awsIamAuthenticator.image }}
+        command:
+        - cp
+        - /aws-iam-authenticator
+        - /shared-bins/aws-iam-authenticator
+        volumeMounts:
+        - name: shared-bins
+          mountPath: /shared-bins
       volumes:
-      - name: slack
-        secret:
-          secretName: slack-token
       - name: hmac
         secret:
           secretName: hmac-token
-      - name: oauth
+      - name: github-token
         secret:
-          secretName: oauth-token
+          secretName: github-token
       - name: config
         configMap:
           name: config
@@ -125,25 +128,9 @@ spec:
       - name: plugins
         configMap:
           name: plugins
-      - name: cat-api
-        configMap:
-          name: cat-api-key
-      - name: unsplash-api
-        secret:
-          secretName: unsplash-api-key
+      - name: shared-bins
+        emptyDir: {}
       - name: kubeconfig
         secret:
-          defaultMode: 420
+          defaultMode: 0644
           secretName: kubeconfig
-      - name: kubeconfig-build-test-infra-trusted
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-test-infra-trusted
-      - name: kubeconfig-build-k8s-prow-builds
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-k8s-prow-builds
-      - name: kubeconfig-build-rules-k8s
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-rules-k8s
diff --git a/config/prow/cluster/hook_rbac.yaml b/config/prow/cluster/hook_rbac.yaml
index 81a9e28df1..9c07a0fafc 100644
--- a/config/prow/cluster/hook_rbac.yaml
+++ b/config/prow/cluster/hook_rbac.yaml
@@ -1,13 +1,13 @@
+{{ if .Values.hook.serviceAccount.create }}
 apiVersion: v1
 kind: ServiceAccount
 metadata:
-  namespace: default
   name: "hook"
+{{ end }}
 ---
 kind: Role
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: "hook"
 rules:
   - apiGroups:
@@ -31,7 +31,6 @@ rules:
 kind: RoleBinding
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: "hook"
 roleRef:
   apiGroup: rbac.authorization.k8s.io
@@ -40,3 +39,4 @@ roleRef:
 subjects:
 - kind: ServiceAccount
   name: "hook"
+  namespace: {{ .Release.Namespace }}
diff --git a/config/prow/cluster/hook_service.yaml b/config/prow/cluster/hook_service.yaml
index f83355a9a7..a636b60490 100644
--- a/config/prow/cluster/hook_service.yaml
+++ b/config/prow/cluster/hook_service.yaml
@@ -15,18 +15,10 @@
 apiVersion: v1
 kind: Service
 metadata:
-  labels:
-    app: hook
-  namespace: default
   name: hook
 spec:
   selector:
     app: hook
   ports:
-  - name: main
-    port: 8888
-    protocol: TCP
-  - name: metrics
-    port: 9090
-    protocol: TCP
-  type: NodePort
+  - port: 8888
+  type: {{ .Values.hook.service.type }}
diff --git a/config/prow/cluster/horologium_deployment.yaml b/config/prow/cluster/horologium_deployment.yaml
index afcc87aa92..a15c7c30cd 100644
--- a/config/prow/cluster/horologium_deployment.yaml
+++ b/config/prow/cluster/horologium_deployment.yaml
@@ -15,7 +15,6 @@
 apiVersion: apps/v1
 kind: Deployment
 metadata:
-  namespace: default
   name: horologium
   labels:
     app: horologium
@@ -28,6 +27,12 @@ spec:
       app: horologium
   template:
     metadata:
+      {{- if .Values.horologium.scrape_metrics }}
+      annotations:
+        prometheus.io/path: /metrics
+        prometheus.io/port: '9090'
+        prometheus.io/scrape: 'true'
+      {{- end }}
       labels:
         app: horologium
     spec:
@@ -35,14 +40,18 @@ spec:
       terminationGracePeriodSeconds: 30
       containers:
       - name: horologium
-        image: gcr.io/k8s-prow/horologium:v20221104-4497ace285
+        image: {{ .Values.horologium.image }}
         args:
         - --config-path=/etc/config/config.yaml
         - --job-config-path=/etc/job-config
-        - --dry-run=false
-        ports:
-        - name: metrics
-          containerPort: 9090
+        - --dry-run={{ .Values.dryRun }}
+        env:
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        - name: AWS_ROLE_SESSION_NAME
+          valueFrom:
+            fieldRef:
+              fieldPath: metadata.name
         volumeMounts:
         - name: config
           mountPath: /etc/config
diff --git a/config/prow/cluster/horologium_rbac.yaml b/config/prow/cluster/horologium_rbac.yaml
index 27c3ce2228..bc61184280 100644
--- a/config/prow/cluster/horologium_rbac.yaml
+++ b/config/prow/cluster/horologium_rbac.yaml
@@ -1,13 +1,13 @@
+{{ if .Values.horologium.serviceAccount.create }}
 apiVersion: v1
 kind: ServiceAccount
 metadata:
-  namespace: default
   name: "horologium"
+{{ end }}
 ---
 kind: Role
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: "horologium"
 rules:
   - apiGroups:
@@ -22,7 +22,6 @@ rules:
 kind: RoleBinding
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: "horologium"
 roleRef:
   apiGroup: rbac.authorization.k8s.io
@@ -31,3 +30,4 @@ roleRef:
 subjects:
 - kind: ServiceAccount
   name: "horologium"
+  namespace: {{ .Release.Namespace }}
diff --git a/config/prow/cluster/prow_controller_manager_deployment.yaml b/config/prow/cluster/prow_controller_manager_deployment.yaml
index a1ec26df3a..0399c1882e 100644
--- a/config/prow/cluster/prow_controller_manager_deployment.yaml
+++ b/config/prow/cluster/prow_controller_manager_deployment.yaml
@@ -15,12 +15,10 @@
 apiVersion: apps/v1
 kind: Deployment
 metadata:
-  namespace: default
   name: prow-controller-manager
   labels:
     app: prow-controller-manager
 spec:
-  # Mutually exclusive with plank. Only one of them may have more than zero replicas.
   replicas: 1
   strategy:
     type: RollingUpdate
@@ -33,44 +31,50 @@ spec:
       app: prow-controller-manager
   template:
     metadata:
+      {{- if .Values.prowControllerManager.scrape_metrics }}
+      annotations:
+        prometheus.io/path: /metrics
+        prometheus.io/port: '9090'
+        prometheus.io/scrape: 'true'
+      {{- end }}
       labels:
         app: prow-controller-manager
     spec:
       serviceAccountName: prow-controller-manager
       containers:
       - name: prow-controller-manager
-        image: gcr.io/k8s-prow/prow-controller-manager:v20221104-4497ace285
+        image: {{ .Values.prowControllerManager.image }}
         args:
         - --config-path=/etc/config/config.yaml
-        - --dry-run=false
+        - --dry-run={{ .Values.dryRun }}
         - --enable-controller=plank
         - --job-config-path=/etc/job-config
+        - --github-token-path=/etc/github/token
+        - --github-endpoint=http://ghproxy
+        - --github-endpoint=https://api.github.com
+        - --kubeconfig=/etc/kubeconfig/config
         env:
-        # Use KUBECONFIG envvar rather than --kubeconfig flag in order to provide multiple configs to merge.
-        - name: KUBECONFIG
-          value: "/etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig:/etc/kubeconfig-build-k8s-prow-builds/kubeconfig:/etc/kubeconfig-build-rules-k8s/kubeconfig"
-        ports:
-        - name: metrics
-          containerPort: 9090
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        - name: AWS_ROLE_SESSION_NAME
+          valueFrom:
+            fieldRef:
+              fieldPath: metadata.name
         volumeMounts:
-        - mountPath: /etc/kubeconfig
-          name: kubeconfig
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-test-infra-trusted
-          name: kubeconfig-build-test-infra-trusted
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-k8s-prow-builds
-          name: kubeconfig-build-k8s-prow-builds
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-rules-k8s
-          name: kubeconfig-build-rules-k8s
-          readOnly: true
         - name: config
           mountPath: /etc/config
           readOnly: true
         - name: job-config
           mountPath: /etc/job-config
           readOnly: true
+        - name: github-token
+          mountPath: /etc/github
+          readOnly: true
+        - name: kubeconfig
+          mountPath: /etc/kubeconfig
+          readOnly: true
+        - name: shared-bins
+          mountPath: /shared-bins
         livenessProbe: # Pod is killed if this fails 3 times.
           httpGet:
             path: /healthz
@@ -83,26 +87,32 @@ spec:
             port: 8081
           initialDelaySeconds: 10
           periodSeconds: 3
+      initContainers:
+      - name: aws-iam-authenticator
+        env:
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        image: {{ .Values.awsIamAuthenticator.image }}
+        command:
+        - cp
+        - /aws-iam-authenticator
+        - /shared-bins/aws-iam-authenticator
+        volumeMounts:
+        - name: shared-bins
+          mountPath: /shared-bins
       volumes:
-      - name: kubeconfig
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig
-      - name: kubeconfig-build-test-infra-trusted
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-test-infra-trusted
-      - name: kubeconfig-build-k8s-prow-builds
+      - name: github-token
         secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-k8s-prow-builds
-      - name: kubeconfig-build-rules-k8s
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-rules-k8s
+          secretName: github-token
       - name: config
         configMap:
           name: config
       - name: job-config
         configMap:
           name: job-config
+      - name: shared-bins
+        emptyDir: {}
+      - name: kubeconfig
+        secret:
+          defaultMode: 0644
+          secretName: kubeconfig
diff --git a/config/prow/cluster/prow_controller_manager_rbac.yaml b/config/prow/cluster/prow_controller_manager_rbac.yaml
index 63e4f5ad56..6b33ac1032 100644
--- a/config/prow/cluster/prow_controller_manager_rbac.yaml
+++ b/config/prow/cluster/prow_controller_manager_rbac.yaml
@@ -12,16 +12,16 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+{{ if .Values.prowControllerManager.serviceAccount.create }}
 apiVersion: v1
 kind: ServiceAccount
 metadata:
-  namespace: default
   name: "prow-controller-manager"
+{{ end }}
 ---
 kind: Role
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: "prow-controller-manager"
 rules:
 - apiGroups:
@@ -61,46 +61,21 @@ rules:
   - prowjobs
   verbs:
   - get
-  - update
   - list
   - watch
   - patch
----
-kind: Role
-apiVersion: rbac.authorization.k8s.io/v1
-metadata:
-  namespace: test-pods
-  name: "prow-controller-manager"
-rules:
 - apiGroups:
-   - ""
+    - ""
   resources:
-  - pods
+    - pods
   verbs:
-  - create
-  - delete
-  - list
-  - watch
-  - get
-  - patch
----
-kind: RoleBinding
-apiVersion: rbac.authorization.k8s.io/v1
-metadata:
-  namespace: default
-  name: "prow-controller-manager"
-roleRef:
-  apiGroup: rbac.authorization.k8s.io
-  kind: Role
-  name: "prow-controller-manager"
-subjects:
-- kind: ServiceAccount
-  name: "prow-controller-manager"
+    - get
+    - list
+    - watch
 ---
 kind: RoleBinding
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: test-pods
   name: "prow-controller-manager"
 roleRef:
   apiGroup: rbac.authorization.k8s.io
@@ -109,4 +84,4 @@ roleRef:
 subjects:
 - kind: ServiceAccount
   name: "prow-controller-manager"
-  namespace: default
+  namespace: {{ .Release.Namespace }}
diff --git a/config/prow/cluster/sinker_deployment.yaml b/config/prow/cluster/sinker_deployment.yaml
index e0fe0b9cd6..d707f54b13 100644
--- a/config/prow/cluster/sinker_deployment.yaml
+++ b/config/prow/cluster/sinker_deployment.yaml
@@ -1,7 +1,6 @@
 apiVersion: apps/v1
 kind: Deployment
 metadata:
-  namespace: default
   name: sinker
   labels:
     app: sinker
@@ -12,63 +11,66 @@ spec:
       app: sinker
   template:
     metadata:
+      {{- if .Values.sinker.scrape_metrics }}
+      annotations:
+        prometheus.io/path: /metrics
+        prometheus.io/port: '9090'
+        prometheus.io/scrape: 'true'
+      {{- end }}
       labels:
         app: sinker
     spec:
       serviceAccountName: sinker
       containers:
       - name: sinker
+        env:
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        - name: AWS_ROLE_SESSION_NAME
+          valueFrom:
+            fieldRef:
+              fieldPath: metadata.name
         args:
+        - --kubeconfig=/etc/kubeconfig/config
         - --config-path=/etc/config/config.yaml
         - --job-config-path=/etc/job-config
-        - --dry-run=false
-        image: gcr.io/k8s-prow/sinker:v20221104-4497ace285
-        env:
-        # Use KUBECONFIG envvar rather than --kubeconfig flag in order to provide multiple configs to merge.
-        - name: KUBECONFIG
-          value: "/etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig:/etc/kubeconfig-build-k8s-prow-builds/kubeconfig:/etc/kubeconfig-build-rules-k8s/kubeconfig"
-        ports:
-        - name: metrics
-          containerPort: 9090
+        - --dry-run={{ .Values.dryRun }}
+        image: {{ .Values.sinker.image }}
         volumeMounts:
-        - mountPath: /etc/kubeconfig
-          name: kubeconfig
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-test-infra-trusted
-          name: kubeconfig-build-test-infra-trusted
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-k8s-prow-builds
-          name: kubeconfig-build-k8s-prow-builds
-          readOnly: true
-        - mountPath: /etc/kubeconfig-build-rules-k8s
-          name: kubeconfig-build-rules-k8s
-          readOnly: true
         - name: config
           mountPath: /etc/config
           readOnly: true
         - name: job-config
           mountPath: /etc/job-config
           readOnly: true
+        - name: kubeconfig
+          mountPath: /etc/kubeconfig
+          readOnly: true
+        - name: shared-bins
+          mountPath: /shared-bins
+      initContainers:
+      - name: aws-iam-authenticator
+        env:
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        image: {{ .Values.awsIamAuthenticator.image }}
+        command:
+        - cp
+        - /aws-iam-authenticator
+        - /shared-bins/aws-iam-authenticator
+        volumeMounts:
+        - name: shared-bins
+          mountPath: /shared-bins
       volumes:
-      - name: kubeconfig
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig
-      - name: kubeconfig-build-test-infra-trusted
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-test-infra-trusted
-      - name: kubeconfig-build-k8s-prow-builds
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-k8s-prow-builds
-      - name: kubeconfig-build-rules-k8s
-        secret:
-          defaultMode: 420
-          secretName: kubeconfig-build-rules-k8s
       - name: config
         configMap:
           name: config
       - name: job-config
         configMap:
           name: job-config
+      - name: shared-bins
+        emptyDir: {}
+      - name: kubeconfig
+        secret:
+          defaultMode: 0644
+          secretName: kubeconfig
diff --git a/config/prow/cluster/sinker_rbac.yaml b/config/prow/cluster/sinker_rbac.yaml
index 70eb9b52bc..87f30fe1d2 100644
--- a/config/prow/cluster/sinker_rbac.yaml
+++ b/config/prow/cluster/sinker_rbac.yaml
@@ -1,13 +1,13 @@
+{{ if .Values.sinker.serviceAccount.create }}
 apiVersion: v1
 kind: ServiceAccount
 metadata:
-  namespace: default
   name: "sinker"
+{{ end }}
 ---
 kind: Role
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: "sinker"
 rules:
   - apiGroups:
@@ -50,41 +50,18 @@ rules:
     - events
     verbs:
     - create
----
-kind: Role
-apiVersion: rbac.authorization.k8s.io/v1
-metadata:
-  namespace: test-pods
-  name: "sinker"
-rules:
   - apiGroups:
-      - ""
+    - ""
     resources:
-      - pods
+    - pods
     verbs:
-      - delete
-      - list
-      - watch
-      - get
-      - patch
----
-kind: RoleBinding
-apiVersion: rbac.authorization.k8s.io/v1
-metadata:
-  namespace: default
-  name: "sinker"
-roleRef:
-  apiGroup: rbac.authorization.k8s.io
-  kind: Role
-  name: "sinker"
-subjects:
-- kind: ServiceAccount
-  name: "sinker"
+    - get
+    - list
+    - watch
 ---
 kind: RoleBinding
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: test-pods
   name: "sinker"
 roleRef:
   apiGroup: rbac.authorization.k8s.io
@@ -93,4 +70,4 @@ roleRef:
 subjects:
 - kind: ServiceAccount
   name: "sinker"
-  namespace: default
+  namespace: {{ .Release.Namespace }}
diff --git a/config/prow/cluster/statusreconciler_deployment.yaml b/config/prow/cluster/statusreconciler_deployment.yaml
index ddc6d45531..6dccad51d6 100644
--- a/config/prow/cluster/statusreconciler_deployment.yaml
+++ b/config/prow/cluster/statusreconciler_deployment.yaml
@@ -15,7 +15,6 @@
 apiVersion: apps/v1
 kind: Deployment
 metadata:
-  namespace: default
   name: statusreconciler
   labels:
     app: statusreconciler
@@ -33,20 +32,28 @@ spec:
       terminationGracePeriodSeconds: 180
       containers:
       - name: statusreconciler
-        image: gcr.io/k8s-prow/status-reconciler:v20221104-4497ace285
+        image: {{ .Values.statusreconciler.image }}
         imagePullPolicy: Always
         args:
-        - --dry-run=false
+        - --dry-run={{ .Values.dryRun }}
         - --continue-on-error=true
         - --plugin-config=/etc/plugins/plugins.yaml
         - --config-path=/etc/config/config.yaml
-        - --github-token-path=/etc/github/oauth
+        - --github-token-path=/etc/github/token
         - --github-endpoint=http://ghproxy
         - --github-endpoint=https://api.github.com
         - --job-config-path=/etc/job-config
-        - --denylist=kubernetes/kubernetes
+        - --s3-credentials-file=/etc/s3-credentials/service-account.json
+        - --status-path=s3://{{ .Values.prow.tideStatusReconcilerBucketName }}/status-reconciler-status
+        env:
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        - name: AWS_ROLE_SESSION_NAME
+          valueFrom:
+            fieldRef:
+              fieldPath: metadata.name
         volumeMounts:
-        - name: oauth
+        - name: github-token
           mountPath: /etc/github
           readOnly: true
         - name: config
@@ -58,10 +65,13 @@ spec:
         - name: plugins
           mountPath: /etc/plugins
           readOnly: true
+        - name: s3-credentials
+          mountPath: /etc/s3-credentials
+          readOnly: true
       volumes:
-      - name: oauth
+      - name: github-token
         secret:
-          secretName: oauth-token
+          secretName: github-token
       - name: config
         configMap:
           name: config
@@ -71,3 +81,6 @@ spec:
       - name: plugins
         configMap:
           name: plugins
+      - name: s3-credentials
+        secret:
+          secretName: s3-credentials
diff --git a/config/prow/cluster/statusreconciler_rbac.yaml b/config/prow/cluster/statusreconciler_rbac.yaml
index 847cfb47c1..1def1c63f7 100644
--- a/config/prow/cluster/statusreconciler_rbac.yaml
+++ b/config/prow/cluster/statusreconciler_rbac.yaml
@@ -1,13 +1,13 @@
+{{ if .Values.statusreconciler.serviceAccount.create }}
 apiVersion: v1
 kind: ServiceAccount
 metadata:
-  namespace: default
   name: statusreconciler
+{{ end }}
 ---
 kind: Role
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: statusreconciler
 rules:
   - apiGroups:
@@ -20,7 +20,6 @@ rules:
 kind: RoleBinding
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: statusreconciler
 roleRef:
   apiGroup: rbac.authorization.k8s.io
@@ -29,3 +28,4 @@ roleRef:
 subjects:
 - kind: ServiceAccount
   name: statusreconciler
+  namespace: {{ .Release.Namespace }}
diff --git a/config/prow/cluster/tide_deployment.yaml b/config/prow/cluster/tide_deployment.yaml
index 54134c3eda..3f9d26f8f4 100644
--- a/config/prow/cluster/tide_deployment.yaml
+++ b/config/prow/cluster/tide_deployment.yaml
@@ -15,7 +15,6 @@
 apiVersion: apps/v1
 kind: Deployment
 metadata:
-  namespace: default
   name: tide
   labels:
     app: tide
@@ -28,29 +27,44 @@ spec:
       app: tide
   template:
     metadata:
+      {{- if .Values.tide.scrape_metrics }}
+      annotations:
+        prometheus.io/path: /metrics
+        prometheus.io/port: '9090'
+        prometheus.io/scrape: 'true'
+      {{- end }}
       labels:
         app: tide
     spec:
       serviceAccountName: tide
       containers:
       - name: tide
-        image: gcr.io/k8s-prow/tide:v20221104-4497ace285
+        image: {{ .Values.tide.image }}
         args:
-        - --dry-run=false
+        - --dry-run={{ .Values.dryRun }}
         - --github-endpoint=http://ghproxy
         - --github-endpoint=https://api.github.com
-        - --github-token-path=/etc/github/oauth
+        - --github-token-path=/etc/github/token
         - --config-path=/etc/config/config.yaml
         - --job-config-path=/etc/job-config
-        - --history-uri=gs://k8s-prow/tide-history.json
-        - --status-path=gs://k8s-prow/tide-status-checkpoint.yaml
+        - --history-uri=s3://{{ .Values.prow.tideStatusReconcilerBucketName }}/tide-history.json
+        - --status-path=s3://{{ .Values.prow.tideStatusReconcilerBucketName }}/tide-status
+        - --github-graphql-endpoint=http://ghproxy/graphql
+        - --s3-credentials-file=/etc/s3-credentials/service-account.json
         ports:
         - name: http
           containerPort: 8888
         - name: metrics
           containerPort: 9090
+        env:
+        - name: AWS_STS_REGIONAL_ENDPOINTS
+          value: regional
+        - name: AWS_ROLE_SESSION_NAME
+          valueFrom:
+            fieldRef:
+              fieldPath: metadata.name
         volumeMounts:
-        - name: oauth
+        - name: github-token
           mountPath: /etc/github
           readOnly: true
         - name: config
@@ -59,13 +73,19 @@ spec:
         - name: job-config
           mountPath: /etc/job-config
           readOnly: true
+        - name: s3-credentials
+          mountPath: /etc/s3-credentials
+          readOnly: true
       volumes:
-      - name: oauth
+      - name: github-token
         secret:
-          secretName: oauth-token
+          secretName: github-token
       - name: config
         configMap:
           name: config
       - name: job-config
         configMap:
           name: job-config
+      - name: s3-credentials
+        secret:
+          secretName: s3-credentials
diff --git a/config/prow/cluster/tide_rbac.yaml b/config/prow/cluster/tide_rbac.yaml
index 65ce3f5704..4c294156ac 100644
--- a/config/prow/cluster/tide_rbac.yaml
+++ b/config/prow/cluster/tide_rbac.yaml
@@ -1,15 +1,13 @@
+{{ if .Values.tide.serviceAccount.create }}
 apiVersion: v1
 kind: ServiceAccount
 metadata:
-  annotations:
-    iam.gke.io/gcp-service-account: control-plane@k8s-prow.iam.gserviceaccount.com
-  namespace: default
   name: tide
+{{ end }}
 ---
 kind: Role
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: tide
 rules:
   - apiGroups:
@@ -25,7 +23,6 @@ rules:
 kind: RoleBinding
 apiVersion: rbac.authorization.k8s.io/v1
 metadata:
-  namespace: default
   name: tide
 roleRef:
   apiGroup: rbac.authorization.k8s.io
@@ -34,3 +31,4 @@ roleRef:
 subjects:
 - kind: ServiceAccount
   name: tide
+  namespace: {{ .Release.Namespace }}
diff --git a/config/prow/cluster/tide_service.yaml b/config/prow/cluster/tide_service.yaml
index 00ba9ae5c0..1195cb16c4 100644
--- a/config/prow/cluster/tide_service.yaml
+++ b/config/prow/cluster/tide_service.yaml
@@ -15,19 +15,10 @@
 apiVersion: v1
 kind: Service
 metadata:
-  labels:
-    app: tide
-  namespace: default
   name: tide
 spec:
   selector:
     app: tide
   ports:
-  - name: main
-    port: 80
+  - port: 80
     targetPort: 8888
-    protocol: TCP
-  - name: metrics
-    port: 9090
-    protocol: TCP
-  type: ClusterIP
diff --git a/config/prow/config.yaml b/config/prow/config.yaml
index 6834bd0182..ae8ea0b0f9 100644
--- a/config/prow/config.yaml
+++ b/config/prow/config.yaml
@@ -215,7 +215,7 @@ slack_reporter_configs:
     job_states_to_report:
       - failure
       - error
-    channel: test-failures
+    channel: modelrocket-prow-failures
     # The template shown below is the default
     report_template: 'Job {{.Spec.Job}} of type {{.Spec.Type}} ended with state {{.Status.State}}. <{{.Status.URL}}|View logs>'
 
-- 
2.39.0

